{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "This script is based on the preprocessing script that Mughda made (https://github.com/seraphinatarrant/embedding_bias/tree/Mugdha). I moved all of the code to ``data_cleaning`` so that it could be more easily accessible in case one of the other scripts needs it. Other than that, I only changed the code so that it would also be usable with csv files.\n",
    "\n",
    "As for the structure of the data, in most of the other scripts I will assume that you saved the data to ``data/archives/2019_03``. If you want to change this, you will have to change that from all of the other scripts. Note that the rest of the code should not have any of that hardcoded for ease of code recycling.\n",
    "\n",
    "We first import all of the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload  \n",
    "import Preprocessing as pre\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is only for debugging and should be removed before uploading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = reload(pre)\n",
    "preprocess_file = pre.preprocess_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean and preprocess the embeddings dataset. This also generates the vocabulary file that will be used for cleaning the downstream dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "\n",
      "Cleaning data...\n",
      "10000 of 1122500 Tweets cleaned\n",
      "20000 of 1122500 Tweets cleaned\n",
      "30000 of 1122500 Tweets cleaned\n",
      "40000 of 1122500 Tweets cleaned\n",
      "50000 of 1122500 Tweets cleaned\n",
      "60000 of 1122500 Tweets cleaned\n",
      "70000 of 1122500 Tweets cleaned\n",
      "80000 of 1122500 Tweets cleaned\n",
      "90000 of 1122500 Tweets cleaned\n",
      "100000 of 1122500 Tweets cleaned\n",
      "110000 of 1122500 Tweets cleaned\n",
      "120000 of 1122500 Tweets cleaned\n",
      "130000 of 1122500 Tweets cleaned\n",
      "140000 of 1122500 Tweets cleaned\n",
      "150000 of 1122500 Tweets cleaned\n",
      "160000 of 1122500 Tweets cleaned\n",
      "170000 of 1122500 Tweets cleaned\n",
      "180000 of 1122500 Tweets cleaned\n",
      "190000 of 1122500 Tweets cleaned\n",
      "200000 of 1122500 Tweets cleaned\n",
      "210000 of 1122500 Tweets cleaned\n",
      "220000 of 1122500 Tweets cleaned\n",
      "230000 of 1122500 Tweets cleaned\n",
      "240000 of 1122500 Tweets cleaned\n",
      "250000 of 1122500 Tweets cleaned\n",
      "260000 of 1122500 Tweets cleaned\n",
      "270000 of 1122500 Tweets cleaned\n",
      "280000 of 1122500 Tweets cleaned\n",
      "290000 of 1122500 Tweets cleaned\n",
      "300000 of 1122500 Tweets cleaned\n",
      "310000 of 1122500 Tweets cleaned\n",
      "320000 of 1122500 Tweets cleaned\n",
      "330000 of 1122500 Tweets cleaned\n",
      "340000 of 1122500 Tweets cleaned\n",
      "350000 of 1122500 Tweets cleaned\n",
      "360000 of 1122500 Tweets cleaned\n",
      "370000 of 1122500 Tweets cleaned\n",
      "380000 of 1122500 Tweets cleaned\n",
      "390000 of 1122500 Tweets cleaned\n",
      "400000 of 1122500 Tweets cleaned\n",
      "410000 of 1122500 Tweets cleaned\n",
      "420000 of 1122500 Tweets cleaned\n",
      "430000 of 1122500 Tweets cleaned\n",
      "440000 of 1122500 Tweets cleaned\n",
      "450000 of 1122500 Tweets cleaned\n",
      "460000 of 1122500 Tweets cleaned\n",
      "470000 of 1122500 Tweets cleaned\n",
      "480000 of 1122500 Tweets cleaned\n",
      "490000 of 1122500 Tweets cleaned\n",
      "500000 of 1122500 Tweets cleaned\n",
      "510000 of 1122500 Tweets cleaned\n",
      "520000 of 1122500 Tweets cleaned\n",
      "530000 of 1122500 Tweets cleaned\n",
      "540000 of 1122500 Tweets cleaned\n",
      "550000 of 1122500 Tweets cleaned\n",
      "560000 of 1122500 Tweets cleaned\n",
      "570000 of 1122500 Tweets cleaned\n",
      "580000 of 1122500 Tweets cleaned\n",
      "590000 of 1122500 Tweets cleaned\n",
      "600000 of 1122500 Tweets cleaned\n",
      "610000 of 1122500 Tweets cleaned\n",
      "620000 of 1122500 Tweets cleaned\n",
      "630000 of 1122500 Tweets cleaned\n",
      "640000 of 1122500 Tweets cleaned\n",
      "650000 of 1122500 Tweets cleaned\n",
      "660000 of 1122500 Tweets cleaned\n",
      "670000 of 1122500 Tweets cleaned\n",
      "680000 of 1122500 Tweets cleaned\n",
      "690000 of 1122500 Tweets cleaned\n",
      "700000 of 1122500 Tweets cleaned\n",
      "710000 of 1122500 Tweets cleaned\n",
      "720000 of 1122500 Tweets cleaned\n",
      "730000 of 1122500 Tweets cleaned\n",
      "740000 of 1122500 Tweets cleaned\n",
      "750000 of 1122500 Tweets cleaned\n",
      "760000 of 1122500 Tweets cleaned\n",
      "770000 of 1122500 Tweets cleaned\n",
      "780000 of 1122500 Tweets cleaned\n",
      "790000 of 1122500 Tweets cleaned\n",
      "800000 of 1122500 Tweets cleaned\n",
      "810000 of 1122500 Tweets cleaned\n",
      "820000 of 1122500 Tweets cleaned\n",
      "830000 of 1122500 Tweets cleaned\n",
      "840000 of 1122500 Tweets cleaned\n",
      "850000 of 1122500 Tweets cleaned\n",
      "860000 of 1122500 Tweets cleaned\n",
      "870000 of 1122500 Tweets cleaned\n",
      "880000 of 1122500 Tweets cleaned\n",
      "890000 of 1122500 Tweets cleaned\n",
      "900000 of 1122500 Tweets cleaned\n",
      "910000 of 1122500 Tweets cleaned\n",
      "920000 of 1122500 Tweets cleaned\n",
      "930000 of 1122500 Tweets cleaned\n",
      "940000 of 1122500 Tweets cleaned\n",
      "950000 of 1122500 Tweets cleaned\n",
      "960000 of 1122500 Tweets cleaned\n",
      "970000 of 1122500 Tweets cleaned\n",
      "980000 of 1122500 Tweets cleaned\n",
      "990000 of 1122500 Tweets cleaned\n",
      "1000000 of 1122500 Tweets cleaned\n",
      "1010000 of 1122500 Tweets cleaned\n",
      "1020000 of 1122500 Tweets cleaned\n",
      "1030000 of 1122500 Tweets cleaned\n",
      "1040000 of 1122500 Tweets cleaned\n",
      "1050000 of 1122500 Tweets cleaned\n",
      "1060000 of 1122500 Tweets cleaned\n",
      "1070000 of 1122500 Tweets cleaned\n",
      "1080000 of 1122500 Tweets cleaned\n",
      "1090000 of 1122500 Tweets cleaned\n",
      "1100000 of 1122500 Tweets cleaned\n",
      "1110000 of 1122500 Tweets cleaned\n",
      "1120000 of 1122500 Tweets cleaned\n",
      "1122500 of 1122500 Tweets cleaned\n",
      "\n",
      "Vocabulary generated\n",
      "\n",
      "367455 words in the vocabulary\n",
      "\n",
      "Preprocessing data...\n",
      "1000 of 1122500 Tweets processed\n",
      "2000 of 1122500 Tweets processed\n",
      "3000 of 1122500 Tweets processed\n",
      "4000 of 1122500 Tweets processed\n",
      "5000 of 1122500 Tweets processed\n",
      "6000 of 1122500 Tweets processed\n",
      "7000 of 1122500 Tweets processed\n",
      "8000 of 1122500 Tweets processed\n",
      "9000 of 1122500 Tweets processed\n",
      "10000 of 1122500 Tweets processed\n",
      "11000 of 1122500 Tweets processed\n",
      "12000 of 1122500 Tweets processed\n",
      "13000 of 1122500 Tweets processed\n",
      "14000 of 1122500 Tweets processed\n",
      "15000 of 1122500 Tweets processed\n",
      "16000 of 1122500 Tweets processed\n",
      "17000 of 1122500 Tweets processed\n",
      "18000 of 1122500 Tweets processed\n",
      "19000 of 1122500 Tweets processed\n",
      "20000 of 1122500 Tweets processed\n",
      "21000 of 1122500 Tweets processed\n",
      "22000 of 1122500 Tweets processed\n",
      "23000 of 1122500 Tweets processed\n",
      "24000 of 1122500 Tweets processed\n",
      "25000 of 1122500 Tweets processed\n",
      "26000 of 1122500 Tweets processed\n",
      "27000 of 1122500 Tweets processed\n",
      "28000 of 1122500 Tweets processed\n",
      "29000 of 1122500 Tweets processed\n",
      "30000 of 1122500 Tweets processed\n",
      "31000 of 1122500 Tweets processed\n",
      "32000 of 1122500 Tweets processed\n",
      "33000 of 1122500 Tweets processed\n",
      "34000 of 1122500 Tweets processed\n",
      "35000 of 1122500 Tweets processed\n",
      "36000 of 1122500 Tweets processed\n",
      "37000 of 1122500 Tweets processed\n",
      "38000 of 1122500 Tweets processed\n",
      "39000 of 1122500 Tweets processed\n",
      "40000 of 1122500 Tweets processed\n",
      "41000 of 1122500 Tweets processed\n",
      "42000 of 1122500 Tweets processed\n",
      "43000 of 1122500 Tweets processed\n",
      "44000 of 1122500 Tweets processed\n",
      "45000 of 1122500 Tweets processed\n",
      "46000 of 1122500 Tweets processed\n",
      "47000 of 1122500 Tweets processed\n",
      "48000 of 1122500 Tweets processed\n",
      "49000 of 1122500 Tweets processed\n",
      "50000 of 1122500 Tweets processed\n",
      "51000 of 1122500 Tweets processed\n",
      "52000 of 1122500 Tweets processed\n",
      "53000 of 1122500 Tweets processed\n",
      "54000 of 1122500 Tweets processed\n",
      "55000 of 1122500 Tweets processed\n",
      "56000 of 1122500 Tweets processed\n",
      "57000 of 1122500 Tweets processed\n",
      "58000 of 1122500 Tweets processed\n",
      "59000 of 1122500 Tweets processed\n",
      "60000 of 1122500 Tweets processed\n",
      "61000 of 1122500 Tweets processed\n",
      "62000 of 1122500 Tweets processed\n",
      "63000 of 1122500 Tweets processed\n",
      "64000 of 1122500 Tweets processed\n",
      "65000 of 1122500 Tweets processed\n",
      "66000 of 1122500 Tweets processed\n",
      "67000 of 1122500 Tweets processed\n",
      "68000 of 1122500 Tweets processed\n",
      "69000 of 1122500 Tweets processed\n",
      "70000 of 1122500 Tweets processed\n",
      "71000 of 1122500 Tweets processed\n",
      "72000 of 1122500 Tweets processed\n",
      "73000 of 1122500 Tweets processed\n",
      "74000 of 1122500 Tweets processed\n",
      "75000 of 1122500 Tweets processed\n",
      "76000 of 1122500 Tweets processed\n",
      "77000 of 1122500 Tweets processed\n",
      "78000 of 1122500 Tweets processed\n",
      "79000 of 1122500 Tweets processed\n",
      "80000 of 1122500 Tweets processed\n",
      "81000 of 1122500 Tweets processed\n",
      "82000 of 1122500 Tweets processed\n",
      "83000 of 1122500 Tweets processed\n",
      "84000 of 1122500 Tweets processed\n",
      "85000 of 1122500 Tweets processed\n",
      "86000 of 1122500 Tweets processed\n",
      "87000 of 1122500 Tweets processed\n",
      "88000 of 1122500 Tweets processed\n",
      "89000 of 1122500 Tweets processed\n",
      "90000 of 1122500 Tweets processed\n",
      "91000 of 1122500 Tweets processed\n",
      "92000 of 1122500 Tweets processed\n",
      "93000 of 1122500 Tweets processed\n",
      "94000 of 1122500 Tweets processed\n",
      "95000 of 1122500 Tweets processed\n",
      "96000 of 1122500 Tweets processed\n",
      "97000 of 1122500 Tweets processed\n",
      "98000 of 1122500 Tweets processed\n",
      "99000 of 1122500 Tweets processed\n",
      "100000 of 1122500 Tweets processed\n",
      "101000 of 1122500 Tweets processed\n",
      "102000 of 1122500 Tweets processed\n",
      "103000 of 1122500 Tweets processed\n",
      "104000 of 1122500 Tweets processed\n",
      "105000 of 1122500 Tweets processed\n",
      "106000 of 1122500 Tweets processed\n",
      "107000 of 1122500 Tweets processed\n",
      "108000 of 1122500 Tweets processed\n",
      "109000 of 1122500 Tweets processed\n",
      "110000 of 1122500 Tweets processed\n",
      "111000 of 1122500 Tweets processed\n",
      "112000 of 1122500 Tweets processed\n",
      "113000 of 1122500 Tweets processed\n",
      "114000 of 1122500 Tweets processed\n",
      "115000 of 1122500 Tweets processed\n",
      "116000 of 1122500 Tweets processed\n",
      "117000 of 1122500 Tweets processed\n",
      "118000 of 1122500 Tweets processed\n",
      "119000 of 1122500 Tweets processed\n",
      "120000 of 1122500 Tweets processed\n",
      "121000 of 1122500 Tweets processed\n",
      "122000 of 1122500 Tweets processed\n",
      "123000 of 1122500 Tweets processed\n",
      "124000 of 1122500 Tweets processed\n",
      "125000 of 1122500 Tweets processed\n",
      "126000 of 1122500 Tweets processed\n",
      "127000 of 1122500 Tweets processed\n",
      "128000 of 1122500 Tweets processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129000 of 1122500 Tweets processed\n",
      "130000 of 1122500 Tweets processed\n",
      "131000 of 1122500 Tweets processed\n",
      "132000 of 1122500 Tweets processed\n",
      "133000 of 1122500 Tweets processed\n",
      "134000 of 1122500 Tweets processed\n",
      "135000 of 1122500 Tweets processed\n",
      "136000 of 1122500 Tweets processed\n",
      "137000 of 1122500 Tweets processed\n",
      "138000 of 1122500 Tweets processed\n",
      "139000 of 1122500 Tweets processed\n",
      "140000 of 1122500 Tweets processed\n",
      "141000 of 1122500 Tweets processed\n",
      "142000 of 1122500 Tweets processed\n",
      "143000 of 1122500 Tweets processed\n",
      "144000 of 1122500 Tweets processed\n",
      "145000 of 1122500 Tweets processed\n",
      "146000 of 1122500 Tweets processed\n",
      "147000 of 1122500 Tweets processed\n",
      "148000 of 1122500 Tweets processed\n",
      "149000 of 1122500 Tweets processed\n",
      "150000 of 1122500 Tweets processed\n",
      "151000 of 1122500 Tweets processed\n",
      "152000 of 1122500 Tweets processed\n",
      "153000 of 1122500 Tweets processed\n",
      "154000 of 1122500 Tweets processed\n",
      "155000 of 1122500 Tweets processed\n",
      "156000 of 1122500 Tweets processed\n",
      "157000 of 1122500 Tweets processed\n",
      "158000 of 1122500 Tweets processed\n",
      "159000 of 1122500 Tweets processed\n",
      "160000 of 1122500 Tweets processed\n",
      "161000 of 1122500 Tweets processed\n",
      "162000 of 1122500 Tweets processed\n",
      "163000 of 1122500 Tweets processed\n",
      "164000 of 1122500 Tweets processed\n",
      "165000 of 1122500 Tweets processed\n",
      "166000 of 1122500 Tweets processed\n",
      "167000 of 1122500 Tweets processed\n",
      "168000 of 1122500 Tweets processed\n",
      "169000 of 1122500 Tweets processed\n",
      "170000 of 1122500 Tweets processed\n",
      "171000 of 1122500 Tweets processed\n",
      "172000 of 1122500 Tweets processed\n",
      "173000 of 1122500 Tweets processed\n",
      "174000 of 1122500 Tweets processed\n",
      "175000 of 1122500 Tweets processed\n",
      "176000 of 1122500 Tweets processed\n",
      "177000 of 1122500 Tweets processed\n",
      "178000 of 1122500 Tweets processed\n",
      "179000 of 1122500 Tweets processed\n",
      "180000 of 1122500 Tweets processed\n",
      "181000 of 1122500 Tweets processed\n",
      "182000 of 1122500 Tweets processed\n",
      "183000 of 1122500 Tweets processed\n",
      "184000 of 1122500 Tweets processed\n",
      "185000 of 1122500 Tweets processed\n",
      "186000 of 1122500 Tweets processed\n",
      "187000 of 1122500 Tweets processed\n",
      "188000 of 1122500 Tweets processed\n",
      "189000 of 1122500 Tweets processed\n",
      "190000 of 1122500 Tweets processed\n",
      "191000 of 1122500 Tweets processed\n",
      "192000 of 1122500 Tweets processed\n",
      "193000 of 1122500 Tweets processed\n",
      "194000 of 1122500 Tweets processed\n",
      "195000 of 1122500 Tweets processed\n",
      "196000 of 1122500 Tweets processed\n",
      "197000 of 1122500 Tweets processed\n",
      "198000 of 1122500 Tweets processed\n",
      "199000 of 1122500 Tweets processed\n",
      "200000 of 1122500 Tweets processed\n",
      "201000 of 1122500 Tweets processed\n",
      "202000 of 1122500 Tweets processed\n",
      "203000 of 1122500 Tweets processed\n",
      "204000 of 1122500 Tweets processed\n",
      "205000 of 1122500 Tweets processed\n",
      "206000 of 1122500 Tweets processed\n",
      "207000 of 1122500 Tweets processed\n",
      "208000 of 1122500 Tweets processed\n",
      "209000 of 1122500 Tweets processed\n",
      "210000 of 1122500 Tweets processed\n",
      "211000 of 1122500 Tweets processed\n",
      "212000 of 1122500 Tweets processed\n",
      "213000 of 1122500 Tweets processed\n",
      "214000 of 1122500 Tweets processed\n",
      "215000 of 1122500 Tweets processed\n",
      "216000 of 1122500 Tweets processed\n",
      "217000 of 1122500 Tweets processed\n",
      "218000 of 1122500 Tweets processed\n",
      "219000 of 1122500 Tweets processed\n",
      "220000 of 1122500 Tweets processed\n",
      "221000 of 1122500 Tweets processed\n",
      "222000 of 1122500 Tweets processed\n",
      "223000 of 1122500 Tweets processed\n",
      "224000 of 1122500 Tweets processed\n",
      "225000 of 1122500 Tweets processed\n",
      "226000 of 1122500 Tweets processed\n",
      "227000 of 1122500 Tweets processed\n",
      "228000 of 1122500 Tweets processed\n",
      "229000 of 1122500 Tweets processed\n",
      "230000 of 1122500 Tweets processed\n",
      "231000 of 1122500 Tweets processed\n",
      "232000 of 1122500 Tweets processed\n",
      "233000 of 1122500 Tweets processed\n",
      "234000 of 1122500 Tweets processed\n",
      "235000 of 1122500 Tweets processed\n",
      "236000 of 1122500 Tweets processed\n",
      "237000 of 1122500 Tweets processed\n",
      "238000 of 1122500 Tweets processed\n",
      "239000 of 1122500 Tweets processed\n",
      "240000 of 1122500 Tweets processed\n",
      "241000 of 1122500 Tweets processed\n",
      "242000 of 1122500 Tweets processed\n",
      "243000 of 1122500 Tweets processed\n",
      "244000 of 1122500 Tweets processed\n",
      "245000 of 1122500 Tweets processed\n",
      "246000 of 1122500 Tweets processed\n",
      "247000 of 1122500 Tweets processed\n",
      "248000 of 1122500 Tweets processed\n",
      "249000 of 1122500 Tweets processed\n",
      "250000 of 1122500 Tweets processed\n",
      "251000 of 1122500 Tweets processed\n",
      "252000 of 1122500 Tweets processed\n",
      "253000 of 1122500 Tweets processed\n",
      "254000 of 1122500 Tweets processed\n",
      "255000 of 1122500 Tweets processed\n",
      "256000 of 1122500 Tweets processed\n",
      "257000 of 1122500 Tweets processed\n",
      "258000 of 1122500 Tweets processed\n",
      "259000 of 1122500 Tweets processed\n",
      "260000 of 1122500 Tweets processed\n",
      "261000 of 1122500 Tweets processed\n",
      "262000 of 1122500 Tweets processed\n",
      "263000 of 1122500 Tweets processed\n",
      "264000 of 1122500 Tweets processed\n",
      "265000 of 1122500 Tweets processed\n",
      "266000 of 1122500 Tweets processed\n",
      "267000 of 1122500 Tweets processed\n",
      "268000 of 1122500 Tweets processed\n",
      "269000 of 1122500 Tweets processed\n",
      "270000 of 1122500 Tweets processed\n",
      "271000 of 1122500 Tweets processed\n",
      "272000 of 1122500 Tweets processed\n",
      "273000 of 1122500 Tweets processed\n",
      "274000 of 1122500 Tweets processed\n",
      "275000 of 1122500 Tweets processed\n",
      "276000 of 1122500 Tweets processed\n",
      "277000 of 1122500 Tweets processed\n",
      "278000 of 1122500 Tweets processed\n",
      "279000 of 1122500 Tweets processed\n",
      "280000 of 1122500 Tweets processed\n",
      "281000 of 1122500 Tweets processed\n",
      "282000 of 1122500 Tweets processed\n",
      "283000 of 1122500 Tweets processed\n",
      "284000 of 1122500 Tweets processed\n",
      "285000 of 1122500 Tweets processed\n",
      "286000 of 1122500 Tweets processed\n",
      "287000 of 1122500 Tweets processed\n",
      "288000 of 1122500 Tweets processed\n",
      "289000 of 1122500 Tweets processed\n",
      "290000 of 1122500 Tweets processed\n",
      "291000 of 1122500 Tweets processed\n",
      "292000 of 1122500 Tweets processed\n",
      "293000 of 1122500 Tweets processed\n",
      "294000 of 1122500 Tweets processed\n",
      "295000 of 1122500 Tweets processed\n",
      "296000 of 1122500 Tweets processed\n",
      "297000 of 1122500 Tweets processed\n",
      "298000 of 1122500 Tweets processed\n",
      "299000 of 1122500 Tweets processed\n",
      "300000 of 1122500 Tweets processed\n",
      "301000 of 1122500 Tweets processed\n",
      "302000 of 1122500 Tweets processed\n",
      "303000 of 1122500 Tweets processed\n",
      "304000 of 1122500 Tweets processed\n",
      "305000 of 1122500 Tweets processed\n",
      "306000 of 1122500 Tweets processed\n",
      "307000 of 1122500 Tweets processed\n",
      "308000 of 1122500 Tweets processed\n",
      "309000 of 1122500 Tweets processed\n",
      "310000 of 1122500 Tweets processed\n",
      "311000 of 1122500 Tweets processed\n",
      "312000 of 1122500 Tweets processed\n",
      "313000 of 1122500 Tweets processed\n",
      "314000 of 1122500 Tweets processed\n",
      "315000 of 1122500 Tweets processed\n",
      "316000 of 1122500 Tweets processed\n",
      "317000 of 1122500 Tweets processed\n",
      "318000 of 1122500 Tweets processed\n",
      "319000 of 1122500 Tweets processed\n",
      "320000 of 1122500 Tweets processed\n",
      "321000 of 1122500 Tweets processed\n",
      "322000 of 1122500 Tweets processed\n",
      "323000 of 1122500 Tweets processed\n",
      "324000 of 1122500 Tweets processed\n",
      "325000 of 1122500 Tweets processed\n",
      "326000 of 1122500 Tweets processed\n",
      "327000 of 1122500 Tweets processed\n",
      "328000 of 1122500 Tweets processed\n",
      "329000 of 1122500 Tweets processed\n",
      "330000 of 1122500 Tweets processed\n",
      "331000 of 1122500 Tweets processed\n",
      "332000 of 1122500 Tweets processed\n",
      "333000 of 1122500 Tweets processed\n",
      "334000 of 1122500 Tweets processed\n",
      "335000 of 1122500 Tweets processed\n",
      "336000 of 1122500 Tweets processed\n",
      "337000 of 1122500 Tweets processed\n",
      "338000 of 1122500 Tweets processed\n",
      "339000 of 1122500 Tweets processed\n",
      "340000 of 1122500 Tweets processed\n",
      "341000 of 1122500 Tweets processed\n",
      "342000 of 1122500 Tweets processed\n",
      "343000 of 1122500 Tweets processed\n",
      "344000 of 1122500 Tweets processed\n",
      "345000 of 1122500 Tweets processed\n",
      "346000 of 1122500 Tweets processed\n",
      "347000 of 1122500 Tweets processed\n",
      "348000 of 1122500 Tweets processed\n",
      "349000 of 1122500 Tweets processed\n",
      "350000 of 1122500 Tweets processed\n",
      "351000 of 1122500 Tweets processed\n",
      "352000 of 1122500 Tweets processed\n",
      "353000 of 1122500 Tweets processed\n",
      "354000 of 1122500 Tweets processed\n",
      "355000 of 1122500 Tweets processed\n",
      "356000 of 1122500 Tweets processed\n",
      "357000 of 1122500 Tweets processed\n",
      "358000 of 1122500 Tweets processed\n",
      "359000 of 1122500 Tweets processed\n",
      "360000 of 1122500 Tweets processed\n",
      "361000 of 1122500 Tweets processed\n",
      "362000 of 1122500 Tweets processed\n",
      "363000 of 1122500 Tweets processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364000 of 1122500 Tweets processed\n",
      "365000 of 1122500 Tweets processed\n",
      "366000 of 1122500 Tweets processed\n",
      "367000 of 1122500 Tweets processed\n",
      "368000 of 1122500 Tweets processed\n",
      "369000 of 1122500 Tweets processed\n",
      "370000 of 1122500 Tweets processed\n",
      "371000 of 1122500 Tweets processed\n",
      "372000 of 1122500 Tweets processed\n",
      "373000 of 1122500 Tweets processed\n",
      "374000 of 1122500 Tweets processed\n",
      "375000 of 1122500 Tweets processed\n",
      "376000 of 1122500 Tweets processed\n",
      "377000 of 1122500 Tweets processed\n",
      "378000 of 1122500 Tweets processed\n",
      "379000 of 1122500 Tweets processed\n",
      "380000 of 1122500 Tweets processed\n",
      "381000 of 1122500 Tweets processed\n",
      "382000 of 1122500 Tweets processed\n",
      "383000 of 1122500 Tweets processed\n",
      "384000 of 1122500 Tweets processed\n",
      "385000 of 1122500 Tweets processed\n",
      "386000 of 1122500 Tweets processed\n",
      "387000 of 1122500 Tweets processed\n",
      "388000 of 1122500 Tweets processed\n",
      "389000 of 1122500 Tweets processed\n",
      "390000 of 1122500 Tweets processed\n",
      "391000 of 1122500 Tweets processed\n",
      "392000 of 1122500 Tweets processed\n",
      "393000 of 1122500 Tweets processed\n",
      "394000 of 1122500 Tweets processed\n",
      "395000 of 1122500 Tweets processed\n",
      "396000 of 1122500 Tweets processed\n",
      "397000 of 1122500 Tweets processed\n",
      "398000 of 1122500 Tweets processed\n",
      "399000 of 1122500 Tweets processed\n",
      "400000 of 1122500 Tweets processed\n",
      "401000 of 1122500 Tweets processed\n",
      "402000 of 1122500 Tweets processed\n",
      "403000 of 1122500 Tweets processed\n",
      "404000 of 1122500 Tweets processed\n",
      "405000 of 1122500 Tweets processed\n",
      "406000 of 1122500 Tweets processed\n",
      "407000 of 1122500 Tweets processed\n",
      "408000 of 1122500 Tweets processed\n",
      "409000 of 1122500 Tweets processed\n",
      "410000 of 1122500 Tweets processed\n",
      "411000 of 1122500 Tweets processed\n",
      "412000 of 1122500 Tweets processed\n",
      "413000 of 1122500 Tweets processed\n",
      "414000 of 1122500 Tweets processed\n",
      "415000 of 1122500 Tweets processed\n",
      "416000 of 1122500 Tweets processed\n",
      "417000 of 1122500 Tweets processed\n",
      "418000 of 1122500 Tweets processed\n",
      "419000 of 1122500 Tweets processed\n",
      "420000 of 1122500 Tweets processed\n",
      "421000 of 1122500 Tweets processed\n",
      "422000 of 1122500 Tweets processed\n",
      "423000 of 1122500 Tweets processed\n",
      "424000 of 1122500 Tweets processed\n",
      "425000 of 1122500 Tweets processed\n",
      "426000 of 1122500 Tweets processed\n",
      "427000 of 1122500 Tweets processed\n",
      "428000 of 1122500 Tweets processed\n",
      "429000 of 1122500 Tweets processed\n",
      "430000 of 1122500 Tweets processed\n",
      "431000 of 1122500 Tweets processed\n",
      "432000 of 1122500 Tweets processed\n",
      "433000 of 1122500 Tweets processed\n",
      "434000 of 1122500 Tweets processed\n",
      "435000 of 1122500 Tweets processed\n",
      "436000 of 1122500 Tweets processed\n",
      "437000 of 1122500 Tweets processed\n",
      "438000 of 1122500 Tweets processed\n",
      "439000 of 1122500 Tweets processed\n",
      "440000 of 1122500 Tweets processed\n",
      "441000 of 1122500 Tweets processed\n",
      "442000 of 1122500 Tweets processed\n",
      "443000 of 1122500 Tweets processed\n",
      "444000 of 1122500 Tweets processed\n",
      "445000 of 1122500 Tweets processed\n",
      "446000 of 1122500 Tweets processed\n",
      "447000 of 1122500 Tweets processed\n",
      "448000 of 1122500 Tweets processed\n",
      "449000 of 1122500 Tweets processed\n",
      "450000 of 1122500 Tweets processed\n",
      "451000 of 1122500 Tweets processed\n",
      "452000 of 1122500 Tweets processed\n",
      "453000 of 1122500 Tweets processed\n",
      "454000 of 1122500 Tweets processed\n",
      "455000 of 1122500 Tweets processed\n",
      "456000 of 1122500 Tweets processed\n",
      "457000 of 1122500 Tweets processed\n",
      "458000 of 1122500 Tweets processed\n",
      "459000 of 1122500 Tweets processed\n",
      "460000 of 1122500 Tweets processed\n",
      "461000 of 1122500 Tweets processed\n",
      "462000 of 1122500 Tweets processed\n",
      "463000 of 1122500 Tweets processed\n",
      "464000 of 1122500 Tweets processed\n",
      "465000 of 1122500 Tweets processed\n",
      "466000 of 1122500 Tweets processed\n",
      "467000 of 1122500 Tweets processed\n",
      "468000 of 1122500 Tweets processed\n",
      "469000 of 1122500 Tweets processed\n",
      "470000 of 1122500 Tweets processed\n",
      "471000 of 1122500 Tweets processed\n",
      "472000 of 1122500 Tweets processed\n",
      "473000 of 1122500 Tweets processed\n",
      "474000 of 1122500 Tweets processed\n",
      "475000 of 1122500 Tweets processed\n",
      "476000 of 1122500 Tweets processed\n",
      "477000 of 1122500 Tweets processed\n",
      "478000 of 1122500 Tweets processed\n",
      "479000 of 1122500 Tweets processed\n",
      "480000 of 1122500 Tweets processed\n",
      "481000 of 1122500 Tweets processed\n",
      "482000 of 1122500 Tweets processed\n",
      "483000 of 1122500 Tweets processed\n",
      "484000 of 1122500 Tweets processed\n",
      "485000 of 1122500 Tweets processed\n",
      "486000 of 1122500 Tweets processed\n",
      "487000 of 1122500 Tweets processed\n",
      "488000 of 1122500 Tweets processed\n",
      "489000 of 1122500 Tweets processed\n",
      "490000 of 1122500 Tweets processed\n",
      "491000 of 1122500 Tweets processed\n",
      "492000 of 1122500 Tweets processed\n",
      "493000 of 1122500 Tweets processed\n",
      "494000 of 1122500 Tweets processed\n",
      "495000 of 1122500 Tweets processed\n",
      "496000 of 1122500 Tweets processed\n",
      "497000 of 1122500 Tweets processed\n",
      "498000 of 1122500 Tweets processed\n",
      "499000 of 1122500 Tweets processed\n",
      "500000 of 1122500 Tweets processed\n",
      "501000 of 1122500 Tweets processed\n",
      "502000 of 1122500 Tweets processed\n",
      "503000 of 1122500 Tweets processed\n",
      "504000 of 1122500 Tweets processed\n",
      "505000 of 1122500 Tweets processed\n",
      "506000 of 1122500 Tweets processed\n",
      "507000 of 1122500 Tweets processed\n",
      "508000 of 1122500 Tweets processed\n",
      "509000 of 1122500 Tweets processed\n",
      "510000 of 1122500 Tweets processed\n",
      "511000 of 1122500 Tweets processed\n",
      "512000 of 1122500 Tweets processed\n",
      "513000 of 1122500 Tweets processed\n",
      "514000 of 1122500 Tweets processed\n",
      "515000 of 1122500 Tweets processed\n",
      "516000 of 1122500 Tweets processed\n",
      "517000 of 1122500 Tweets processed\n",
      "518000 of 1122500 Tweets processed\n",
      "519000 of 1122500 Tweets processed\n",
      "520000 of 1122500 Tweets processed\n",
      "521000 of 1122500 Tweets processed\n",
      "522000 of 1122500 Tweets processed\n",
      "523000 of 1122500 Tweets processed\n",
      "524000 of 1122500 Tweets processed\n",
      "525000 of 1122500 Tweets processed\n",
      "526000 of 1122500 Tweets processed\n",
      "527000 of 1122500 Tweets processed\n",
      "528000 of 1122500 Tweets processed\n",
      "529000 of 1122500 Tweets processed\n",
      "530000 of 1122500 Tweets processed\n",
      "531000 of 1122500 Tweets processed\n",
      "532000 of 1122500 Tweets processed\n",
      "533000 of 1122500 Tweets processed\n",
      "534000 of 1122500 Tweets processed\n",
      "535000 of 1122500 Tweets processed\n",
      "536000 of 1122500 Tweets processed\n",
      "537000 of 1122500 Tweets processed\n",
      "538000 of 1122500 Tweets processed\n",
      "539000 of 1122500 Tweets processed\n",
      "540000 of 1122500 Tweets processed\n",
      "541000 of 1122500 Tweets processed\n",
      "542000 of 1122500 Tweets processed\n",
      "543000 of 1122500 Tweets processed\n",
      "544000 of 1122500 Tweets processed\n",
      "545000 of 1122500 Tweets processed\n",
      "546000 of 1122500 Tweets processed\n",
      "547000 of 1122500 Tweets processed\n",
      "548000 of 1122500 Tweets processed\n",
      "549000 of 1122500 Tweets processed\n",
      "550000 of 1122500 Tweets processed\n",
      "551000 of 1122500 Tweets processed\n",
      "552000 of 1122500 Tweets processed\n",
      "553000 of 1122500 Tweets processed\n",
      "554000 of 1122500 Tweets processed\n",
      "555000 of 1122500 Tweets processed\n",
      "556000 of 1122500 Tweets processed\n",
      "557000 of 1122500 Tweets processed\n",
      "558000 of 1122500 Tweets processed\n",
      "559000 of 1122500 Tweets processed\n",
      "560000 of 1122500 Tweets processed\n",
      "561000 of 1122500 Tweets processed\n",
      "562000 of 1122500 Tweets processed\n",
      "563000 of 1122500 Tweets processed\n",
      "564000 of 1122500 Tweets processed\n",
      "565000 of 1122500 Tweets processed\n",
      "566000 of 1122500 Tweets processed\n",
      "567000 of 1122500 Tweets processed\n",
      "568000 of 1122500 Tweets processed\n",
      "569000 of 1122500 Tweets processed\n",
      "570000 of 1122500 Tweets processed\n",
      "571000 of 1122500 Tweets processed\n",
      "572000 of 1122500 Tweets processed\n",
      "573000 of 1122500 Tweets processed\n",
      "574000 of 1122500 Tweets processed\n",
      "575000 of 1122500 Tweets processed\n",
      "576000 of 1122500 Tweets processed\n",
      "577000 of 1122500 Tweets processed\n",
      "578000 of 1122500 Tweets processed\n",
      "579000 of 1122500 Tweets processed\n",
      "580000 of 1122500 Tweets processed\n",
      "581000 of 1122500 Tweets processed\n",
      "582000 of 1122500 Tweets processed\n",
      "583000 of 1122500 Tweets processed\n",
      "584000 of 1122500 Tweets processed\n",
      "585000 of 1122500 Tweets processed\n",
      "586000 of 1122500 Tweets processed\n",
      "587000 of 1122500 Tweets processed\n",
      "588000 of 1122500 Tweets processed\n",
      "589000 of 1122500 Tweets processed\n",
      "590000 of 1122500 Tweets processed\n",
      "591000 of 1122500 Tweets processed\n",
      "592000 of 1122500 Tweets processed\n",
      "593000 of 1122500 Tweets processed\n",
      "594000 of 1122500 Tweets processed\n",
      "595000 of 1122500 Tweets processed\n",
      "596000 of 1122500 Tweets processed\n",
      "597000 of 1122500 Tweets processed\n",
      "598000 of 1122500 Tweets processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599000 of 1122500 Tweets processed\n",
      "600000 of 1122500 Tweets processed\n",
      "601000 of 1122500 Tweets processed\n",
      "602000 of 1122500 Tweets processed\n",
      "603000 of 1122500 Tweets processed\n",
      "604000 of 1122500 Tweets processed\n",
      "605000 of 1122500 Tweets processed\n",
      "606000 of 1122500 Tweets processed\n",
      "607000 of 1122500 Tweets processed\n",
      "608000 of 1122500 Tweets processed\n",
      "609000 of 1122500 Tweets processed\n",
      "610000 of 1122500 Tweets processed\n",
      "611000 of 1122500 Tweets processed\n",
      "612000 of 1122500 Tweets processed\n",
      "613000 of 1122500 Tweets processed\n",
      "614000 of 1122500 Tweets processed\n",
      "615000 of 1122500 Tweets processed\n",
      "616000 of 1122500 Tweets processed\n",
      "617000 of 1122500 Tweets processed\n",
      "618000 of 1122500 Tweets processed\n",
      "619000 of 1122500 Tweets processed\n",
      "620000 of 1122500 Tweets processed\n",
      "621000 of 1122500 Tweets processed\n",
      "622000 of 1122500 Tweets processed\n",
      "623000 of 1122500 Tweets processed\n",
      "624000 of 1122500 Tweets processed\n",
      "625000 of 1122500 Tweets processed\n",
      "626000 of 1122500 Tweets processed\n",
      "627000 of 1122500 Tweets processed\n",
      "628000 of 1122500 Tweets processed\n",
      "629000 of 1122500 Tweets processed\n",
      "630000 of 1122500 Tweets processed\n",
      "631000 of 1122500 Tweets processed\n",
      "632000 of 1122500 Tweets processed\n",
      "633000 of 1122500 Tweets processed\n",
      "634000 of 1122500 Tweets processed\n",
      "635000 of 1122500 Tweets processed\n",
      "636000 of 1122500 Tweets processed\n",
      "637000 of 1122500 Tweets processed\n",
      "638000 of 1122500 Tweets processed\n",
      "639000 of 1122500 Tweets processed\n",
      "640000 of 1122500 Tweets processed\n",
      "641000 of 1122500 Tweets processed\n",
      "642000 of 1122500 Tweets processed\n",
      "643000 of 1122500 Tweets processed\n",
      "644000 of 1122500 Tweets processed\n",
      "645000 of 1122500 Tweets processed\n",
      "646000 of 1122500 Tweets processed\n",
      "647000 of 1122500 Tweets processed\n",
      "648000 of 1122500 Tweets processed\n",
      "649000 of 1122500 Tweets processed\n",
      "650000 of 1122500 Tweets processed\n",
      "651000 of 1122500 Tweets processed\n",
      "652000 of 1122500 Tweets processed\n",
      "653000 of 1122500 Tweets processed\n",
      "654000 of 1122500 Tweets processed\n",
      "655000 of 1122500 Tweets processed\n",
      "656000 of 1122500 Tweets processed\n",
      "657000 of 1122500 Tweets processed\n",
      "658000 of 1122500 Tweets processed\n",
      "659000 of 1122500 Tweets processed\n",
      "660000 of 1122500 Tweets processed\n",
      "661000 of 1122500 Tweets processed\n",
      "662000 of 1122500 Tweets processed\n",
      "663000 of 1122500 Tweets processed\n",
      "664000 of 1122500 Tweets processed\n",
      "665000 of 1122500 Tweets processed\n",
      "666000 of 1122500 Tweets processed\n",
      "667000 of 1122500 Tweets processed\n",
      "668000 of 1122500 Tweets processed\n",
      "669000 of 1122500 Tweets processed\n",
      "670000 of 1122500 Tweets processed\n",
      "671000 of 1122500 Tweets processed\n",
      "672000 of 1122500 Tweets processed\n",
      "673000 of 1122500 Tweets processed\n",
      "674000 of 1122500 Tweets processed\n",
      "675000 of 1122500 Tweets processed\n",
      "676000 of 1122500 Tweets processed\n",
      "677000 of 1122500 Tweets processed\n",
      "678000 of 1122500 Tweets processed\n",
      "679000 of 1122500 Tweets processed\n",
      "680000 of 1122500 Tweets processed\n",
      "681000 of 1122500 Tweets processed\n",
      "682000 of 1122500 Tweets processed\n",
      "683000 of 1122500 Tweets processed\n",
      "684000 of 1122500 Tweets processed\n",
      "685000 of 1122500 Tweets processed\n",
      "686000 of 1122500 Tweets processed\n",
      "687000 of 1122500 Tweets processed\n",
      "688000 of 1122500 Tweets processed\n",
      "689000 of 1122500 Tweets processed\n",
      "690000 of 1122500 Tweets processed\n",
      "691000 of 1122500 Tweets processed\n",
      "692000 of 1122500 Tweets processed\n",
      "693000 of 1122500 Tweets processed\n",
      "694000 of 1122500 Tweets processed\n",
      "695000 of 1122500 Tweets processed\n",
      "696000 of 1122500 Tweets processed\n",
      "697000 of 1122500 Tweets processed\n",
      "698000 of 1122500 Tweets processed\n",
      "699000 of 1122500 Tweets processed\n",
      "700000 of 1122500 Tweets processed\n",
      "701000 of 1122500 Tweets processed\n",
      "702000 of 1122500 Tweets processed\n",
      "703000 of 1122500 Tweets processed\n",
      "704000 of 1122500 Tweets processed\n",
      "705000 of 1122500 Tweets processed\n",
      "706000 of 1122500 Tweets processed\n",
      "707000 of 1122500 Tweets processed\n",
      "708000 of 1122500 Tweets processed\n",
      "709000 of 1122500 Tweets processed\n",
      "710000 of 1122500 Tweets processed\n",
      "711000 of 1122500 Tweets processed\n",
      "712000 of 1122500 Tweets processed\n",
      "713000 of 1122500 Tweets processed\n",
      "714000 of 1122500 Tweets processed\n",
      "715000 of 1122500 Tweets processed\n",
      "716000 of 1122500 Tweets processed\n",
      "717000 of 1122500 Tweets processed\n",
      "718000 of 1122500 Tweets processed\n",
      "719000 of 1122500 Tweets processed\n",
      "720000 of 1122500 Tweets processed\n",
      "721000 of 1122500 Tweets processed\n",
      "722000 of 1122500 Tweets processed\n",
      "723000 of 1122500 Tweets processed\n",
      "724000 of 1122500 Tweets processed\n",
      "725000 of 1122500 Tweets processed\n",
      "726000 of 1122500 Tweets processed\n",
      "727000 of 1122500 Tweets processed\n",
      "728000 of 1122500 Tweets processed\n",
      "729000 of 1122500 Tweets processed\n",
      "730000 of 1122500 Tweets processed\n",
      "731000 of 1122500 Tweets processed\n",
      "732000 of 1122500 Tweets processed\n",
      "733000 of 1122500 Tweets processed\n",
      "734000 of 1122500 Tweets processed\n",
      "735000 of 1122500 Tweets processed\n",
      "736000 of 1122500 Tweets processed\n",
      "737000 of 1122500 Tweets processed\n",
      "738000 of 1122500 Tweets processed\n",
      "739000 of 1122500 Tweets processed\n",
      "740000 of 1122500 Tweets processed\n",
      "741000 of 1122500 Tweets processed\n",
      "742000 of 1122500 Tweets processed\n",
      "743000 of 1122500 Tweets processed\n",
      "744000 of 1122500 Tweets processed\n",
      "745000 of 1122500 Tweets processed\n",
      "746000 of 1122500 Tweets processed\n",
      "747000 of 1122500 Tweets processed\n",
      "748000 of 1122500 Tweets processed\n",
      "749000 of 1122500 Tweets processed\n",
      "750000 of 1122500 Tweets processed\n",
      "751000 of 1122500 Tweets processed\n",
      "752000 of 1122500 Tweets processed\n",
      "753000 of 1122500 Tweets processed\n",
      "754000 of 1122500 Tweets processed\n",
      "755000 of 1122500 Tweets processed\n",
      "756000 of 1122500 Tweets processed\n",
      "757000 of 1122500 Tweets processed\n",
      "758000 of 1122500 Tweets processed\n",
      "759000 of 1122500 Tweets processed\n",
      "760000 of 1122500 Tweets processed\n",
      "761000 of 1122500 Tweets processed\n",
      "762000 of 1122500 Tweets processed\n",
      "763000 of 1122500 Tweets processed\n",
      "764000 of 1122500 Tweets processed\n",
      "765000 of 1122500 Tweets processed\n",
      "766000 of 1122500 Tweets processed\n",
      "767000 of 1122500 Tweets processed\n",
      "768000 of 1122500 Tweets processed\n",
      "769000 of 1122500 Tweets processed\n",
      "770000 of 1122500 Tweets processed\n",
      "771000 of 1122500 Tweets processed\n",
      "772000 of 1122500 Tweets processed\n",
      "773000 of 1122500 Tweets processed\n",
      "774000 of 1122500 Tweets processed\n",
      "775000 of 1122500 Tweets processed\n",
      "776000 of 1122500 Tweets processed\n",
      "777000 of 1122500 Tweets processed\n",
      "778000 of 1122500 Tweets processed\n",
      "779000 of 1122500 Tweets processed\n",
      "780000 of 1122500 Tweets processed\n",
      "781000 of 1122500 Tweets processed\n",
      "782000 of 1122500 Tweets processed\n",
      "783000 of 1122500 Tweets processed\n",
      "784000 of 1122500 Tweets processed\n",
      "785000 of 1122500 Tweets processed\n",
      "786000 of 1122500 Tweets processed\n",
      "787000 of 1122500 Tweets processed\n",
      "788000 of 1122500 Tweets processed\n",
      "789000 of 1122500 Tweets processed\n",
      "790000 of 1122500 Tweets processed\n",
      "791000 of 1122500 Tweets processed\n",
      "792000 of 1122500 Tweets processed\n",
      "793000 of 1122500 Tweets processed\n",
      "794000 of 1122500 Tweets processed\n",
      "795000 of 1122500 Tweets processed\n",
      "796000 of 1122500 Tweets processed\n",
      "797000 of 1122500 Tweets processed\n",
      "798000 of 1122500 Tweets processed\n",
      "799000 of 1122500 Tweets processed\n",
      "800000 of 1122500 Tweets processed\n",
      "801000 of 1122500 Tweets processed\n",
      "802000 of 1122500 Tweets processed\n",
      "803000 of 1122500 Tweets processed\n",
      "804000 of 1122500 Tweets processed\n",
      "805000 of 1122500 Tweets processed\n",
      "806000 of 1122500 Tweets processed\n",
      "807000 of 1122500 Tweets processed\n",
      "808000 of 1122500 Tweets processed\n",
      "809000 of 1122500 Tweets processed\n",
      "810000 of 1122500 Tweets processed\n",
      "811000 of 1122500 Tweets processed\n",
      "812000 of 1122500 Tweets processed\n",
      "813000 of 1122500 Tweets processed\n",
      "814000 of 1122500 Tweets processed\n",
      "815000 of 1122500 Tweets processed\n",
      "816000 of 1122500 Tweets processed\n",
      "817000 of 1122500 Tweets processed\n",
      "818000 of 1122500 Tweets processed\n",
      "819000 of 1122500 Tweets processed\n",
      "820000 of 1122500 Tweets processed\n",
      "821000 of 1122500 Tweets processed\n",
      "822000 of 1122500 Tweets processed\n",
      "823000 of 1122500 Tweets processed\n",
      "824000 of 1122500 Tweets processed\n",
      "825000 of 1122500 Tweets processed\n",
      "826000 of 1122500 Tweets processed\n",
      "827000 of 1122500 Tweets processed\n",
      "828000 of 1122500 Tweets processed\n",
      "829000 of 1122500 Tweets processed\n",
      "830000 of 1122500 Tweets processed\n",
      "831000 of 1122500 Tweets processed\n",
      "832000 of 1122500 Tweets processed\n",
      "833000 of 1122500 Tweets processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834000 of 1122500 Tweets processed\n",
      "835000 of 1122500 Tweets processed\n",
      "836000 of 1122500 Tweets processed\n",
      "837000 of 1122500 Tweets processed\n",
      "838000 of 1122500 Tweets processed\n",
      "839000 of 1122500 Tweets processed\n",
      "840000 of 1122500 Tweets processed\n",
      "841000 of 1122500 Tweets processed\n",
      "842000 of 1122500 Tweets processed\n",
      "843000 of 1122500 Tweets processed\n",
      "844000 of 1122500 Tweets processed\n",
      "845000 of 1122500 Tweets processed\n",
      "846000 of 1122500 Tweets processed\n",
      "847000 of 1122500 Tweets processed\n",
      "848000 of 1122500 Tweets processed\n",
      "849000 of 1122500 Tweets processed\n",
      "850000 of 1122500 Tweets processed\n",
      "851000 of 1122500 Tweets processed\n",
      "852000 of 1122500 Tweets processed\n",
      "853000 of 1122500 Tweets processed\n",
      "854000 of 1122500 Tweets processed\n",
      "855000 of 1122500 Tweets processed\n",
      "856000 of 1122500 Tweets processed\n",
      "857000 of 1122500 Tweets processed\n",
      "858000 of 1122500 Tweets processed\n",
      "859000 of 1122500 Tweets processed\n",
      "860000 of 1122500 Tweets processed\n",
      "861000 of 1122500 Tweets processed\n",
      "862000 of 1122500 Tweets processed\n",
      "863000 of 1122500 Tweets processed\n",
      "864000 of 1122500 Tweets processed\n",
      "865000 of 1122500 Tweets processed\n",
      "866000 of 1122500 Tweets processed\n",
      "867000 of 1122500 Tweets processed\n",
      "868000 of 1122500 Tweets processed\n",
      "869000 of 1122500 Tweets processed\n",
      "870000 of 1122500 Tweets processed\n",
      "871000 of 1122500 Tweets processed\n",
      "872000 of 1122500 Tweets processed\n",
      "873000 of 1122500 Tweets processed\n",
      "874000 of 1122500 Tweets processed\n",
      "875000 of 1122500 Tweets processed\n",
      "876000 of 1122500 Tweets processed\n",
      "877000 of 1122500 Tweets processed\n",
      "878000 of 1122500 Tweets processed\n",
      "879000 of 1122500 Tweets processed\n",
      "880000 of 1122500 Tweets processed\n",
      "881000 of 1122500 Tweets processed\n",
      "882000 of 1122500 Tweets processed\n",
      "883000 of 1122500 Tweets processed\n",
      "884000 of 1122500 Tweets processed\n",
      "885000 of 1122500 Tweets processed\n",
      "886000 of 1122500 Tweets processed\n",
      "887000 of 1122500 Tweets processed\n",
      "888000 of 1122500 Tweets processed\n",
      "889000 of 1122500 Tweets processed\n",
      "890000 of 1122500 Tweets processed\n",
      "891000 of 1122500 Tweets processed\n",
      "892000 of 1122500 Tweets processed\n",
      "893000 of 1122500 Tweets processed\n",
      "894000 of 1122500 Tweets processed\n",
      "895000 of 1122500 Tweets processed\n",
      "896000 of 1122500 Tweets processed\n",
      "897000 of 1122500 Tweets processed\n",
      "898000 of 1122500 Tweets processed\n",
      "899000 of 1122500 Tweets processed\n",
      "900000 of 1122500 Tweets processed\n",
      "901000 of 1122500 Tweets processed\n",
      "902000 of 1122500 Tweets processed\n",
      "903000 of 1122500 Tweets processed\n",
      "904000 of 1122500 Tweets processed\n",
      "905000 of 1122500 Tweets processed\n",
      "906000 of 1122500 Tweets processed\n",
      "907000 of 1122500 Tweets processed\n",
      "908000 of 1122500 Tweets processed\n",
      "909000 of 1122500 Tweets processed\n",
      "910000 of 1122500 Tweets processed\n",
      "911000 of 1122500 Tweets processed\n",
      "912000 of 1122500 Tweets processed\n",
      "913000 of 1122500 Tweets processed\n",
      "914000 of 1122500 Tweets processed\n",
      "915000 of 1122500 Tweets processed\n",
      "916000 of 1122500 Tweets processed\n",
      "917000 of 1122500 Tweets processed\n",
      "918000 of 1122500 Tweets processed\n",
      "919000 of 1122500 Tweets processed\n",
      "920000 of 1122500 Tweets processed\n",
      "921000 of 1122500 Tweets processed\n",
      "922000 of 1122500 Tweets processed\n",
      "923000 of 1122500 Tweets processed\n",
      "924000 of 1122500 Tweets processed\n",
      "925000 of 1122500 Tweets processed\n",
      "926000 of 1122500 Tweets processed\n",
      "927000 of 1122500 Tweets processed\n",
      "928000 of 1122500 Tweets processed\n",
      "929000 of 1122500 Tweets processed\n",
      "930000 of 1122500 Tweets processed\n",
      "931000 of 1122500 Tweets processed\n",
      "932000 of 1122500 Tweets processed\n",
      "933000 of 1122500 Tweets processed\n",
      "934000 of 1122500 Tweets processed\n",
      "935000 of 1122500 Tweets processed\n",
      "936000 of 1122500 Tweets processed\n",
      "937000 of 1122500 Tweets processed\n",
      "938000 of 1122500 Tweets processed\n",
      "939000 of 1122500 Tweets processed\n",
      "940000 of 1122500 Tweets processed\n",
      "941000 of 1122500 Tweets processed\n",
      "942000 of 1122500 Tweets processed\n",
      "943000 of 1122500 Tweets processed\n",
      "944000 of 1122500 Tweets processed\n",
      "945000 of 1122500 Tweets processed\n",
      "946000 of 1122500 Tweets processed\n",
      "947000 of 1122500 Tweets processed\n",
      "948000 of 1122500 Tweets processed\n",
      "949000 of 1122500 Tweets processed\n",
      "950000 of 1122500 Tweets processed\n",
      "951000 of 1122500 Tweets processed\n",
      "952000 of 1122500 Tweets processed\n",
      "953000 of 1122500 Tweets processed\n",
      "954000 of 1122500 Tweets processed\n",
      "955000 of 1122500 Tweets processed\n",
      "956000 of 1122500 Tweets processed\n",
      "957000 of 1122500 Tweets processed\n",
      "958000 of 1122500 Tweets processed\n",
      "959000 of 1122500 Tweets processed\n",
      "960000 of 1122500 Tweets processed\n",
      "961000 of 1122500 Tweets processed\n",
      "962000 of 1122500 Tweets processed\n",
      "963000 of 1122500 Tweets processed\n",
      "964000 of 1122500 Tweets processed\n",
      "965000 of 1122500 Tweets processed\n",
      "966000 of 1122500 Tweets processed\n",
      "967000 of 1122500 Tweets processed\n",
      "968000 of 1122500 Tweets processed\n",
      "969000 of 1122500 Tweets processed\n",
      "970000 of 1122500 Tweets processed\n",
      "971000 of 1122500 Tweets processed\n",
      "972000 of 1122500 Tweets processed\n",
      "973000 of 1122500 Tweets processed\n",
      "974000 of 1122500 Tweets processed\n",
      "975000 of 1122500 Tweets processed\n",
      "976000 of 1122500 Tweets processed\n",
      "977000 of 1122500 Tweets processed\n",
      "978000 of 1122500 Tweets processed\n",
      "979000 of 1122500 Tweets processed\n",
      "980000 of 1122500 Tweets processed\n",
      "981000 of 1122500 Tweets processed\n",
      "982000 of 1122500 Tweets processed\n",
      "983000 of 1122500 Tweets processed\n",
      "984000 of 1122500 Tweets processed\n",
      "985000 of 1122500 Tweets processed\n",
      "986000 of 1122500 Tweets processed\n",
      "987000 of 1122500 Tweets processed\n",
      "988000 of 1122500 Tweets processed\n",
      "989000 of 1122500 Tweets processed\n",
      "990000 of 1122500 Tweets processed\n",
      "991000 of 1122500 Tweets processed\n",
      "992000 of 1122500 Tweets processed\n",
      "993000 of 1122500 Tweets processed\n",
      "994000 of 1122500 Tweets processed\n",
      "995000 of 1122500 Tweets processed\n",
      "996000 of 1122500 Tweets processed\n",
      "997000 of 1122500 Tweets processed\n",
      "998000 of 1122500 Tweets processed\n",
      "999000 of 1122500 Tweets processed\n",
      "1000000 of 1122500 Tweets processed\n",
      "1001000 of 1122500 Tweets processed\n",
      "1002000 of 1122500 Tweets processed\n",
      "1003000 of 1122500 Tweets processed\n",
      "1004000 of 1122500 Tweets processed\n",
      "1005000 of 1122500 Tweets processed\n",
      "1006000 of 1122500 Tweets processed\n",
      "1007000 of 1122500 Tweets processed\n",
      "1008000 of 1122500 Tweets processed\n",
      "1009000 of 1122500 Tweets processed\n",
      "1010000 of 1122500 Tweets processed\n",
      "1011000 of 1122500 Tweets processed\n",
      "1012000 of 1122500 Tweets processed\n",
      "1013000 of 1122500 Tweets processed\n",
      "1014000 of 1122500 Tweets processed\n",
      "1015000 of 1122500 Tweets processed\n",
      "1016000 of 1122500 Tweets processed\n",
      "1017000 of 1122500 Tweets processed\n",
      "1018000 of 1122500 Tweets processed\n",
      "1019000 of 1122500 Tweets processed\n",
      "1020000 of 1122500 Tweets processed\n",
      "1021000 of 1122500 Tweets processed\n",
      "1022000 of 1122500 Tweets processed\n",
      "1023000 of 1122500 Tweets processed\n",
      "1024000 of 1122500 Tweets processed\n",
      "1025000 of 1122500 Tweets processed\n",
      "1026000 of 1122500 Tweets processed\n",
      "1027000 of 1122500 Tweets processed\n",
      "1028000 of 1122500 Tweets processed\n",
      "1029000 of 1122500 Tweets processed\n",
      "1030000 of 1122500 Tweets processed\n",
      "1031000 of 1122500 Tweets processed\n",
      "1032000 of 1122500 Tweets processed\n",
      "1033000 of 1122500 Tweets processed\n",
      "1034000 of 1122500 Tweets processed\n",
      "1035000 of 1122500 Tweets processed\n",
      "1036000 of 1122500 Tweets processed\n",
      "1037000 of 1122500 Tweets processed\n",
      "1038000 of 1122500 Tweets processed\n",
      "1039000 of 1122500 Tweets processed\n",
      "1040000 of 1122500 Tweets processed\n",
      "1041000 of 1122500 Tweets processed\n",
      "1042000 of 1122500 Tweets processed\n",
      "1043000 of 1122500 Tweets processed\n",
      "1044000 of 1122500 Tweets processed\n",
      "1045000 of 1122500 Tweets processed\n",
      "1046000 of 1122500 Tweets processed\n",
      "1047000 of 1122500 Tweets processed\n",
      "1048000 of 1122500 Tweets processed\n",
      "1049000 of 1122500 Tweets processed\n",
      "1050000 of 1122500 Tweets processed\n",
      "1051000 of 1122500 Tweets processed\n",
      "1052000 of 1122500 Tweets processed\n",
      "1053000 of 1122500 Tweets processed\n",
      "1054000 of 1122500 Tweets processed\n",
      "1055000 of 1122500 Tweets processed\n",
      "1056000 of 1122500 Tweets processed\n",
      "1057000 of 1122500 Tweets processed\n",
      "1058000 of 1122500 Tweets processed\n",
      "1059000 of 1122500 Tweets processed\n",
      "1060000 of 1122500 Tweets processed\n",
      "1061000 of 1122500 Tweets processed\n",
      "1062000 of 1122500 Tweets processed\n",
      "1063000 of 1122500 Tweets processed\n",
      "1064000 of 1122500 Tweets processed\n",
      "1065000 of 1122500 Tweets processed\n",
      "1066000 of 1122500 Tweets processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067000 of 1122500 Tweets processed\n",
      "1068000 of 1122500 Tweets processed\n",
      "1069000 of 1122500 Tweets processed\n",
      "1070000 of 1122500 Tweets processed\n",
      "1071000 of 1122500 Tweets processed\n",
      "1072000 of 1122500 Tweets processed\n",
      "1073000 of 1122500 Tweets processed\n",
      "1074000 of 1122500 Tweets processed\n",
      "1075000 of 1122500 Tweets processed\n",
      "1076000 of 1122500 Tweets processed\n",
      "1077000 of 1122500 Tweets processed\n",
      "1078000 of 1122500 Tweets processed\n",
      "1079000 of 1122500 Tweets processed\n",
      "1080000 of 1122500 Tweets processed\n",
      "1081000 of 1122500 Tweets processed\n",
      "1082000 of 1122500 Tweets processed\n",
      "1083000 of 1122500 Tweets processed\n",
      "1084000 of 1122500 Tweets processed\n",
      "1085000 of 1122500 Tweets processed\n",
      "1086000 of 1122500 Tweets processed\n",
      "1087000 of 1122500 Tweets processed\n",
      "1088000 of 1122500 Tweets processed\n",
      "1089000 of 1122500 Tweets processed\n",
      "1090000 of 1122500 Tweets processed\n",
      "1091000 of 1122500 Tweets processed\n",
      "1092000 of 1122500 Tweets processed\n",
      "1093000 of 1122500 Tweets processed\n",
      "1094000 of 1122500 Tweets processed\n",
      "1095000 of 1122500 Tweets processed\n",
      "1096000 of 1122500 Tweets processed\n",
      "1097000 of 1122500 Tweets processed\n",
      "1098000 of 1122500 Tweets processed\n",
      "1099000 of 1122500 Tweets processed\n",
      "1100000 of 1122500 Tweets processed\n",
      "1101000 of 1122500 Tweets processed\n",
      "1102000 of 1122500 Tweets processed\n",
      "1103000 of 1122500 Tweets processed\n",
      "1104000 of 1122500 Tweets processed\n",
      "1105000 of 1122500 Tweets processed\n",
      "1106000 of 1122500 Tweets processed\n",
      "1107000 of 1122500 Tweets processed\n",
      "1108000 of 1122500 Tweets processed\n",
      "1109000 of 1122500 Tweets processed\n",
      "1110000 of 1122500 Tweets processed\n",
      "1111000 of 1122500 Tweets processed\n",
      "1112000 of 1122500 Tweets processed\n",
      "1113000 of 1122500 Tweets processed\n",
      "1114000 of 1122500 Tweets processed\n",
      "1115000 of 1122500 Tweets processed\n",
      "1116000 of 1122500 Tweets processed\n",
      "1117000 of 1122500 Tweets processed\n",
      "1118000 of 1122500 Tweets processed\n",
      "1119000 of 1122500 Tweets processed\n",
      "1120000 of 1122500 Tweets processed\n",
      "1121000 of 1122500 Tweets processed\n",
      "1122000 of 1122500 Tweets processed\n",
      "1122500 of 1122500 Tweets processed\n",
      "\n",
      "Saving data...\n",
      "Data successfully saved!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#path = \"../../train_data/twitter_es/2019_03/tweets_{}_14_to_31.tsv\"\n",
    "#path = \"../../train_data/twitter_en/2018/10/01/tweets_{}_01.tsv\"\n",
    "path = \"../../train_data/twitter_es/2019_04/tweets_{}_all.tsv\"\n",
    "origin_path = path.format(\"clean\")\n",
    "save_path = path.format(\"processed\")\n",
    "\n",
    "#with open(origin_path) as fin:\n",
    "#    lines = fin.readlines()\n",
    "#print(lines[0])\n",
    "\n",
    "vocab = preprocess_file(origin_path, save_path, \"txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary length sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate the preprocessed dataset for the downstream task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "\n",
      "Cleaning data...\n",
      "1000 of 1000 Tweets cleaned\n",
      "\n",
      "Vocabulary generated\n",
      "\n",
      "5149 words in the vocabulary\n",
      "\n",
      "Preprocessing data...\n",
      "1000 of 1000 Tweets processed\n",
      "1000 of 1000 Tweets processed\n",
      "\n",
      "Saving data...\n",
      "Data successfully saved!\n",
      "\n",
      "\n",
      "\n",
      "Importing data...\n",
      "\n",
      "Cleaning data...\n",
      "9000 of 9000 Tweets cleaned\n",
      "\n",
      "Vocabulary generated\n",
      "\n",
      "18075 words in the vocabulary\n",
      "\n",
      "Preprocessing data...\n",
      "1000 of 9000 Tweets processed\n",
      "2000 of 9000 Tweets processed\n",
      "3000 of 9000 Tweets processed\n",
      "4000 of 9000 Tweets processed\n",
      "5000 of 9000 Tweets processed\n",
      "6000 of 9000 Tweets processed\n",
      "7000 of 9000 Tweets processed\n",
      "8000 of 9000 Tweets processed\n",
      "9000 of 9000 Tweets processed\n",
      "9000 of 9000 Tweets processed\n",
      "\n",
      "Saving data...\n",
      "Data successfully saved!\n",
      "\n",
      "\n",
      "\n",
      "Importing data...\n",
      "\n",
      "Cleaning data...\n",
      "3000 of 3000 Tweets cleaned\n",
      "\n",
      "Vocabulary generated\n",
      "\n",
      "8862 words in the vocabulary\n",
      "\n",
      "Preprocessing data...\n",
      "1000 of 3000 Tweets processed\n",
      "2000 of 3000 Tweets processed\n",
      "3000 of 3000 Tweets processed\n",
      "3000 of 3000 Tweets processed\n",
      "\n",
      "Saving data...\n",
      "Data successfully saved!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "origin = '../../data/hateval2019/hateval2019_en_'\n",
    "save = '../../data/hateval2019/hateval2019_clean_en_'\n",
    "files = [\"dev\", \"train\", \"test\"]\n",
    "\n",
    "for file in files:\n",
    "    origin_path = origin + file + \".csv\"\n",
    "    save_path = save + file + \".csv\"\n",
    "\n",
    "    preprocess_file(origin_path, save_path, \"DataFrame\")#, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 4 fields in line 15, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-055781a07cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/embed_bias/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/embed_bias/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/embed_bias/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/embed_bias/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 4 fields in line 15, saw 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(save_path, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                               text  HS  TR  AG\n",
      "0  34243  <MENTION> <MENTION> <MENTION> oh , i could hav...   0   0   0\n",
      "1  30593  several of the wild fires in <HASH> california...   0   0   0\n",
      "2  31427  <MENTION> my question is how do you resettle a...   0   0   0\n",
      "3  31694  <HASH> europe , you've got a problem ! we must...   1   0   0\n",
      "4  31865  this is outrageous ! <HASH> stopillegalimmigra...   1   0   0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_bias",
   "language": "python",
   "name": "embed_bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
