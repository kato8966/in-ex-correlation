{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Join the Raw Twitter TSV Files\n",
    "\n",
    "The `filter_by_language` notebook takes each day's tweets and, well, filters them by language. This notebook takes all of the days within a month and joins them. If you have another month's data, join that first and rename it to `00_clean.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Preprocessing import fetch_longtweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and get a set of the headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seraphinagoldfarb-tarrant/PycharmProjects/embedding_bias/scripts/data_cleaning'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "head = set([])\n",
    "\n",
    "path = \"../../train_data/twitter_es/2019_03/\"\n",
    "\n",
    "#for a in range(0,3):\n",
    "    #for b in range(0,10):\n",
    "        #day = str(a) + str(b)\n",
    "        #print(day)\n",
    "for day in range(14,32):\n",
    "    try:\n",
    "        df = pd.read_csv(path+str(day)+\"_clean.tsv\", index_col=\"id\", sep=\"\\t\", dtype=str).fillna(\"\")\n",
    "        data.append(df)\n",
    "        head = head.union(set(df.columns))\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        #print(\"oh, no\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is if there is just one file\n",
    "path = \"../../train_data/twitter_en/2018/10/01/\"\n",
    "df = pd.read_csv(path+\"01_clean.tsv\",index_col=\"id\", sep=\"\\t\", dtype=str).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = set([])\n",
    "head = head.union(set(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the data for all of the days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595685, 36)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(data, sort=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all of the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place', 'in_reply_to_user_id_str', 'retweet_count', 'extended_tweet', 'source', 'possibly_sensitive', 'retweeted_status', 'favorite_count', 'retweeted', 'display_text_range', 'truncated', 'in_reply_to_status_id', 'favorited', 'in_reply_to_screen_name', 'timestamp_ms', 'id_str', 'quoted_status', 'filter_level', 'geo', 'in_reply_to_status_id_str', 'lang', 'in_reply_to_user_id', 'quoted_status_id', 'withheld_in_countries', 'created_at', 'user', 'entities', 'coordinates', 'extended_entities', 'is_quote_status', 'contributors', 'quoted_status_id_str', 'quoted_status_permalink', 'quote_count', 'reply_count', 'text'}\n"
     ]
    }
   ],
   "source": [
    "#print(set(df.columns))\n",
    "print(head)\n",
    "hds = set(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a sanity check to see that no data was excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(head.symmetric_difference(set(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to a tsv file. This should be the one used to preprocess the data and any other sort of manipulation that we want to do with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path+\"no_RTs.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 595684 Tweets fetched...\n",
      "10000 of 595684 Tweets fetched...\n",
      "20000 of 595684 Tweets fetched...\n",
      "30000 of 595684 Tweets fetched...\n",
      "40000 of 595684 Tweets fetched...\n",
      "50000 of 595684 Tweets fetched...\n",
      "60000 of 595684 Tweets fetched...\n",
      "70000 of 595684 Tweets fetched...\n",
      "80000 of 595684 Tweets fetched...\n",
      "90000 of 595684 Tweets fetched...\n",
      "100000 of 595684 Tweets fetched...\n",
      "110000 of 595684 Tweets fetched...\n",
      "120000 of 595684 Tweets fetched...\n",
      "130000 of 595684 Tweets fetched...\n",
      "140000 of 595684 Tweets fetched...\n",
      "150000 of 595684 Tweets fetched...\n",
      "160000 of 595684 Tweets fetched...\n",
      "170000 of 595684 Tweets fetched...\n",
      "180000 of 595684 Tweets fetched...\n",
      "190000 of 595684 Tweets fetched...\n",
      "200000 of 595684 Tweets fetched...\n",
      "210000 of 595684 Tweets fetched...\n",
      "220000 of 595684 Tweets fetched...\n",
      "230000 of 595684 Tweets fetched...\n",
      "240000 of 595684 Tweets fetched...\n",
      "250000 of 595684 Tweets fetched...\n",
      "260000 of 595684 Tweets fetched...\n",
      "270000 of 595684 Tweets fetched...\n",
      "280000 of 595684 Tweets fetched...\n",
      "290000 of 595684 Tweets fetched...\n",
      "300000 of 595684 Tweets fetched...\n",
      "310000 of 595684 Tweets fetched...\n",
      "320000 of 595684 Tweets fetched...\n",
      "330000 of 595684 Tweets fetched...\n",
      "340000 of 595684 Tweets fetched...\n",
      "350000 of 595684 Tweets fetched...\n",
      "360000 of 595684 Tweets fetched...\n",
      "370000 of 595684 Tweets fetched...\n",
      "380000 of 595684 Tweets fetched...\n",
      "390000 of 595684 Tweets fetched...\n",
      "400000 of 595684 Tweets fetched...\n",
      "410000 of 595684 Tweets fetched...\n",
      "420000 of 595684 Tweets fetched...\n",
      "430000 of 595684 Tweets fetched...\n",
      "440000 of 595684 Tweets fetched...\n",
      "450000 of 595684 Tweets fetched...\n",
      "460000 of 595684 Tweets fetched...\n",
      "470000 of 595684 Tweets fetched...\n",
      "480000 of 595684 Tweets fetched...\n",
      "490000 of 595684 Tweets fetched...\n",
      "500000 of 595684 Tweets fetched...\n",
      "510000 of 595684 Tweets fetched...\n",
      "520000 of 595684 Tweets fetched...\n",
      "530000 of 595684 Tweets fetched...\n",
      "540000 of 595684 Tweets fetched...\n",
      "550000 of 595684 Tweets fetched...\n",
      "560000 of 595684 Tweets fetched...\n",
      "570000 of 595684 Tweets fetched...\n",
      "580000 of 595684 Tweets fetched...\n",
      "590000 of 595684 Tweets fetched...\n",
      "595684 of 595684 Tweets fetched...\n"
     ]
    }
   ],
   "source": [
    "tweets = fetch_longtweet(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(path+\"tweets_clean_01.tsv\",sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_bias",
   "language": "python",
   "name": "embed_bias"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
